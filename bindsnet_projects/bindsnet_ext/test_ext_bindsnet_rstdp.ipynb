{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef4d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from time import time as t\n",
    "\n",
    "from bindsnetExt.Datasets import *\n",
    "from bindsnetExt.Network import *\n",
    "from bindsnetExt.Learning import *\n",
    "\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_weights, get_square_assignments\n",
    "from bindsnet.evaluation import all_activity, proportion_weighting, assign_labels\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df3a8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExperiment(params, lrnArgs, p_type, save_data = True):\n",
    "        \n",
    "         \n",
    "         \n",
    "    if p_type == \"ppx\":\n",
    "        LR = ppxPostPre\n",
    "    elif p_type == \"nc\":\n",
    "        LR = ncPostPre\n",
    "    else:\n",
    "        LR = PostPre\n",
    "\n",
    "    \n",
    "    time = int(params[\"time\"])\n",
    "    intensity = params[\"intensity\"]\n",
    "    n_neurons = int(params[\"n_neurons\"])\n",
    "    dt = params['dt']\n",
    "    \n",
    "    \n",
    "    progress_interval = 3\n",
    "    update_interval = int(params[\"update_interval\"])\n",
    "    seed = 0\n",
    "    n_epochs = int(params[\"n_epochs\"])\n",
    "    n_workers = 0\n",
    "\n",
    "    gpu = params[\"gpu\"]\n",
    "    \n",
    "    excArgs = {'rest':params[\"rest\"],\n",
    "               'reset':params[\"reset\"],\n",
    "               'thresh':params['thresh'], \n",
    "               'refrac':params['refrac'], \n",
    "               'tc_decay':params['tc_decay'], \n",
    "               'tc_trace':params[\"tc_trace\"]}\n",
    "    \n",
    "    lrn_keys = [key for key in lrnArgs]\n",
    "    \n",
    "    nu = (lrnArgs[lrn_keys[1]], lrnArgs[lrn_keys[0]])\n",
    "\n",
    "    # Sets up Gpu use\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if gpu and torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    else:\n",
    "        torch.manual_seed(seed)\n",
    "        device = \"cpu\"\n",
    "        if gpu:\n",
    "            gpu = False\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.set_num_threads(os.cpu_count() - 1)\n",
    "    print(\"Running on Device = \", device)\n",
    "    \n",
    "    \n",
    "    X, Y = load_digits(n_class=10, return_X_y=True, as_frame=False)\n",
    "    \n",
    "    n_inpt = X.shape[-1]\n",
    "\n",
    "    \n",
    "        \n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = seed)\n",
    "    \n",
    "    accs = []\n",
    "    prop = []\n",
    "    logreg = []\n",
    "    \n",
    "    fold_num = 0\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X,Y):\n",
    "        \n",
    "        # Build network.\n",
    "        network = DiehlAndCook(\n",
    "            LearningRule = LR,\n",
    "            n_inpt=n_inpt,\n",
    "            nu = nu,\n",
    "            wmin = 0.,\n",
    "            wmax = 1.,\n",
    "            inh=params[\"inh\"],\n",
    "            inpt_shape=(1, int(np.sqrt(n_inpt)), int(np.sqrt(n_inpt))),\n",
    "            n_neurons = n_neurons,\n",
    "            theta_plus = 0.07,\n",
    "            dt = dt,\n",
    "            norm = params[\"norm\"],\n",
    "            tc_theta_decay = 7e6,\n",
    "            lrnArgs = lrnArgs,\n",
    "            excArgs = excArgs,   \n",
    "        )\n",
    "\n",
    "        LM = LogisticRegression(C=params[\"C\"])\n",
    "\n",
    "\n",
    "        # Directs network to GPU\n",
    "        if gpu:\n",
    "            network.to(\"cuda\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        x_train, y_train = X[train_idx], Y[train_idx]\n",
    "        x_test, y_test = X[test_idx], Y[test_idx]\n",
    "        \n",
    "\n",
    "        train_dataset = bnDataset(\n",
    "                                PoissonEncoder(time=time, dt=dt),\n",
    "                                None,\n",
    "                                transform=transforms.Compose(\n",
    "                                    [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "                                ),\n",
    "\n",
    "                                  subset_x = x_train, \n",
    "                                  subset_y = y_train, \n",
    "                                  shape = (int(np.sqrt(n_inpt)), int(np.sqrt(n_inpt))),\n",
    "                                 )\n",
    "\n",
    "        test_dataset = bnDataset(\n",
    "                                PoissonEncoder(time=time, dt=dt),\n",
    "                                None,\n",
    "                                transform=transforms.Compose(\n",
    "                                    [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "                                ),\n",
    "\n",
    "                                  subset_x = x_test, \n",
    "                                  subset_y = y_test, \n",
    "                                  shape = (int(np.sqrt(n_inpt)), int(np.sqrt(n_inpt))),\n",
    "                                 )\n",
    "\n",
    "\n",
    "        n_train = len(train_dataset) // 10\n",
    "        print(\"n_train: \", n_train)\n",
    "\n",
    "        # Record spikes during the simulation.\n",
    "        spike_record = torch.zeros((update_interval, int(time / dt), n_neurons), device=device)\n",
    "\n",
    "        # Neuron assignments and spike proportions.\n",
    "        n_classes = len(np.unique(Y))\n",
    "        assignments = -torch.ones(n_neurons, device=device)\n",
    "        proportions = torch.zeros((n_neurons, n_classes), device=device)\n",
    "        rates = torch.zeros((n_neurons, n_classes), device=device)\n",
    "\n",
    "\n",
    "        # Set up monitors for spikes and voltages\n",
    "        spikes = {}\n",
    "        for layer in set(network.layers):\n",
    "            spikes[layer] = Monitor(\n",
    "                network.layers[layer], state_vars=[\"s\"], time=int(time / dt)\n",
    "            )\n",
    "            network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "        # Train the network.\n",
    "        print(\"\\nBegin training.\\n\")\n",
    "#         print(\"network layers: \", network.layers)\n",
    "        start = t()\n",
    "        for epoch in range(n_epochs):\n",
    "            labels = []\n",
    "\n",
    "            if epoch % progress_interval == 0:\n",
    "                #print(\"Progress: %d / %d (%.4f seconds)\" % (epoch, n_epochs, t() - start))\n",
    "                start = t()\n",
    "\n",
    "            # Create a dataloader to iterate and batch data\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                train_dataset, batch_size=1, shuffle=True, num_workers=n_workers, pin_memory=gpu\n",
    "            )\n",
    "\n",
    "            for step, batch in enumerate(dataloader):\n",
    "                if step > n_train:\n",
    "                    break\n",
    "                # Get next input sample.\n",
    "                inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, int(np.sqrt(n_inpt)), int(np.sqrt(n_inpt)))}\n",
    "                if gpu:\n",
    "                    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "                    \n",
    "                network.train(False)\n",
    "                # Run the network on the input.\n",
    "                network.run(inputs=inputs, time=time, input_time_dim=1)\n",
    "                \n",
    "                # Add to spikes recording.\n",
    "                spike_record[step % update_interval] = spikes[\"Y\"].get(\"s\").squeeze()\n",
    "\n",
    "                # Convert the array of labels into a tensor\n",
    "                label_tensor = torch.tensor(labels, device=device)\n",
    "\n",
    "                # Get network predictions.\n",
    "                all_activity_pred = all_activity(\n",
    "                    spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "                )\n",
    "\n",
    "                proportion_pred = proportion_weighting(\n",
    "                    spikes=spike_record,\n",
    "                    assignments=assignments,\n",
    "                    proportions=proportions,\n",
    "                    n_labels=n_classes,\n",
    "                )\n",
    "\n",
    "\n",
    "                # Assign labels to excitatory layer neurons.\n",
    "                assignments, proportions, rates = assign_labels(\n",
    "                    spikes=spike_record,\n",
    "                    labels=label_tensor,\n",
    "                    n_labels=n_classes,\n",
    "                    rates=rates,\n",
    "                )\n",
    "\n",
    "                labels = []\n",
    "\n",
    "                labels.append(batch[\"label\"])\n",
    "                \n",
    "                y_act = all_activity_pred.cpu().numpy()\n",
    "                y_prop = proportion_pred.cpu().numpy()\n",
    "                \n",
    "                if (y_act == batch[\"label\"]):\n",
    "                    reward = 1\n",
    "                else:\n",
    "                    reward = -1\n",
    "                    \n",
    "                network.reset_state_variables()  # Reset state variables.\n",
    "                \n",
    "                network.train(True)\n",
    "                network.run(inputs=inputs, time=time, input_time_dim=1, reward=reward)\n",
    "                \n",
    "                network.reset_state_variables()  # Reset state variables.\n",
    "\n",
    "\n",
    "        n_test = len(test_dataset) // 10\n",
    "\n",
    "        # Sequence of accuracy estimates.\n",
    "        accuracy = {\"all\": 0, \"proportion\": 0}\n",
    "\n",
    "        # Record spikes during the simulation.\n",
    "        spike_record = torch.zeros((1, int(time / dt), n_neurons), device=device)\n",
    "\n",
    "        # Train the network.\n",
    "        print(\"\\nBegin testing\\n\")\n",
    "        network.train(mode=False)\n",
    "        start = t()\n",
    "        \n",
    "        y_act = []\n",
    "        y_prop = []\n",
    "\n",
    "        #pbar = tqdm(total=n_test)\n",
    "        for step, batch in enumerate(test_dataset):\n",
    "            if step >= n_test:\n",
    "                break\n",
    "            # Get next input sample.\n",
    "            inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, int(np.sqrt(n_inpt)), int(np.sqrt(n_inpt)))}\n",
    "            if gpu:\n",
    "                inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "            # Run the network on the input.\n",
    "            network.run(inputs=inputs, time=time, input_time_dim=1)\n",
    "\n",
    "            # Add to spikes recording.\n",
    "            spike_record[0] = spikes[\"Y\"].get(\"s\").squeeze()\n",
    "\n",
    "            # Convert the array of labels into a tensor\n",
    "            label_tensor = torch.tensor(batch[\"label\"], device=device)\n",
    "\n",
    "            # Get network predictions.\n",
    "            all_activity_pred = all_activity(\n",
    "                spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "            )\n",
    "\n",
    "            proportion_pred = proportion_weighting(\n",
    "                spikes=spike_record,\n",
    "                assignments=assignments,\n",
    "                proportions=proportions,\n",
    "                n_labels=n_classes,\n",
    "            )\n",
    "            \n",
    "\n",
    "            # Compute network accuracy according to available classification strategies.\n",
    "            accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n",
    "            accuracy[\"proportion\"] += float(\n",
    "                torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "            )\n",
    "            \n",
    "            y_act.append(all_activity_pred.cpu().numpy())\n",
    "            y_prop.append(proportion_pred.cpu().numpy())\n",
    "\n",
    "\n",
    "            network.reset_state_variables()  # Reset state variables.\n",
    "        \n",
    "        if save_data:\n",
    "        \n",
    "            with open(f\"./expResults/digits_labels/fold_{fold_num}_activity_pred_{p_type}.pkl\", 'wb') as f:\n",
    "                pickle.dump(np.asarray(y_act), f)\n",
    "\n",
    "            with open(f\"./expResults/digits_labels/fold_{fold_num}_proportion_pred_{p_type}.pkl\", 'wb') as f:\n",
    "                pickle.dump(np.asarray(y_prop), f)\n",
    "\n",
    "\n",
    "            weights = network.connections[('X', 'Y')].w.cpu().numpy()\n",
    "            \n",
    "            with open(f\"./expResults/digits_weights/fold_{fold_num}_weights_{p_type}.pkl\", 'wb') as f:\n",
    "                pickle.dump(weights, f)\n",
    "                \n",
    "            with open(f\"./expResults/digits_assignments/fold_{fold_num}_assignments_{p_type}.pkl\", 'wb') as f:\n",
    "                pickle.dump(assignments.cpu().numpy(), f)\n",
    "                \n",
    "            with open(f\"./expResults/digits_indexing/fold_{fold_num}_train_idx_{p_type}.pkl\", 'wb') as f:\n",
    "                pickle.dump(train_idx, f)\n",
    "        \n",
    "            \n",
    "        fold_num+=1\n",
    "        \n",
    "        print(\"Testing complete.\\n\")\n",
    "        \n",
    "        acc = accuracy[\"all\"]/n_test\n",
    "        print(acc)\n",
    "        \n",
    "        accs.append(acc)\n",
    "        prop.append(accuracy[\"proportion\"]/n_test)\n",
    "        \n",
    "        del train_dataset\n",
    "        del test_dataset\n",
    "        del network\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        \n",
    "    print(f\"voting accuracy: {np.mean(accs)}\")\n",
    "    print(f\"voting proportion accuracy: {np.mean(prop)}\")\n",
    "        \n",
    "    return (accs, prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd28bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Parameters/digits_memristors.json\", 'r', encoding='utf-8') as f:\n",
    "        parameters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c689ddf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ppx': [{'time': 15,\n",
       "   'dt': 1,\n",
       "   'n_neurons': 160,\n",
       "   'intensity': 82.69,\n",
       "   'update_interval': 1,\n",
       "   'inh': 15.2,\n",
       "   'rest': -65,\n",
       "   'reset': -65,\n",
       "   'thresh': -28.83,\n",
       "   'refrac': 5.78,\n",
       "   'tc_decay': 120.29,\n",
       "   'tc_trace': 10,\n",
       "   'norm': 62.14,\n",
       "   'n_epochs': 3,\n",
       "   'gpu': True,\n",
       "   'C': 1000.0},\n",
       "  {'alpha_pos': 0.316,\n",
       "   'alpha_neg': 0.011,\n",
       "   'beta_pre': 2.213,\n",
       "   'beta_post': -5.969,\n",
       "   'gamma_pre': 0.032,\n",
       "   'gamma_post': 0.146}],\n",
       " 'ppx_rstdp': [{'time': 15,\n",
       "   'dt': 1,\n",
       "   'n_neurons': 160,\n",
       "   'intensity': 82.69,\n",
       "   'update_interval': 1,\n",
       "   'inh': 15.2,\n",
       "   'rest': -65,\n",
       "   'reset': -65,\n",
       "   'thresh': -28.83,\n",
       "   'refrac': 5.78,\n",
       "   'tc_decay': 120.29,\n",
       "   'tc_trace': 10,\n",
       "   'norm': 62.14,\n",
       "   'n_epochs': 3,\n",
       "   'gpu': True,\n",
       "   'C': 1000.0},\n",
       "  {'alpha_pos': 0.316,\n",
       "   'alpha_neg': 0.011,\n",
       "   'beta_pre': 2.213,\n",
       "   'beta_post': -5.969,\n",
       "   'gamma_pre': 0.032,\n",
       "   'gamma_post': 0.146}],\n",
       " 'nc': [{'time': 300,\n",
       "   'dt': 1,\n",
       "   'n_neurons': 1600,\n",
       "   'intensity': 3.98,\n",
       "   'update_interval': 300,\n",
       "   'inh': 17.5,\n",
       "   'rest': -65,\n",
       "   'reset': -65,\n",
       "   'thresh': -42.08,\n",
       "   'refrac': 3.4,\n",
       "   'tc_decay': 109.74,\n",
       "   'tc_trace': 10,\n",
       "   'norm': 36.76,\n",
       "   'n_epochs': 3,\n",
       "   'gpu': True,\n",
       "   'C': 1000.0},\n",
       "  {'A_pos': 0.074,\n",
       "   'A_neg': 0.047,\n",
       "   'mu_pre': 26.7,\n",
       "   'mu_post': -22.3,\n",
       "   'tau_pre': 9.3,\n",
       "   'tau_post': -10.8}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "699d7032",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'ppx_rstdp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a2890b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device =  cpu\n",
      "n_train:  143\n",
      "\n",
      "Begin training.\n",
      "\n",
      "\n",
      "Begin testing\n",
      "\n",
      "Testing complete.\n",
      "\n",
      "0.027777777777777776\n",
      "n_train:  143\n",
      "\n",
      "Begin training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp = runExperiment(parameters[key][0], parameters[key][1], key, save_data = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0404c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23337722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4517e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9339b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b2ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_torch",
   "language": "python",
   "name": "rl_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
