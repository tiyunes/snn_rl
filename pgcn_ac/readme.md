Использование метода обучения [PGCN (Policy Gradient Coagent Network)](https://arxiv.org/pdf/2005.05941.pdf) для решения задачи контроля в среде **Acrobot**

Графики награды на **обучающих** итерациях:

![График награды на обучающих итерациях](https://github.com/tiyunes/snn_rl/assets/79756733/a522074e-bbc4-477c-90ad-4daf25125950)
![plot_acrobot_1_moving_avg_30_trial](https://github.com/tiyunes/snn_rl/assets/79756733/9a7c0db9-6e78-401d-8c1f-8333dc2d769f)
![plot_acrobot_1_moving_avg_10_trial](https://github.com/tiyunes/snn_rl/assets/79756733/4bbc44a9-822e-4744-adc6-8205db375e6e)

Графики награды на **тестовых** итерациях:

![plot_acrobot_test_1](https://github.com/tiyunes/snn_rl/assets/79756733/2350b0a0-4682-474a-b17e-ba7edc2aeb68)
![plot_acrobot_test_1_moving_avg_5_trial](https://github.com/tiyunes/snn_rl/assets/79756733/a8c903f9-c176-417b-9c2b-fd83c20c249b)

Среднее значение награды на 50 **тестовых** эпизодах: -168.62 

Решение задачи управления в среде **Cartpole** (воспроизведение результатов):

![Figure 2023-12-17 022328](https://github.com/tiyunes/snn_rl/assets/79756733/4db9ba99-11d8-4a75-b1e3-b2582234de8d)
